思路说明

1. 项目目标与背景
本项目旨在利用多智能体强化学习（MARL）方法，模拟和优化海上油污扩散应急响应。通过异构船只协作，实现油污高效清理、围堵和分散，提升应急决策智能化水平。

2. 系统结构与主要模块
- 环境模块（EnhancedOilSpillEnvironment）：负责油污扩散、船只移动、环境变化等仿真，支持PyGNOME物理模型和简化模拟。
- 智能体模块（EnhancedMADDPGAgent）：每个船只为一个智能体，具备独立Actor-Critic网络，支持异构类型（清污、围堵、分散）。
- 神经网络模块：包括图神经网络（GNN）编码器、时序编码器（LSTM+Attention）、类型特定网络等。
- 经验回放与优先级采样（PrioritizedReplayBuffer）：提升采样效率和训练稳定性。
- 训练主控与并行机制：支持多进程采样、TensorBoard日志、模型保存与曲线绘制。

3. 强化学习算法与改进点
- 基于MADDPG（Multi-Agent Deep Deterministic Policy Gradient）框架，支持多智能体协作与对抗。
- Actor网络集成GNN（空间关系）、LSTM+Attention（时序特征）、类型特定分支，提升异构智能体表达能力。
- Critic网络融合全局状态、动作和图特征，实现全局价值评估。
- 优先级经验回放（PER）提升采样效率，支持TD误差动态调整优先级。

4. 环境建模与奖励设计
- 环境支持真实物理模拟（PyGNOME）和简化油污扩散。
- 状态空间包含船只自身、相对位置、油污信息、环境参数等。
- 动作空间涵盖移动、作业强度、燃油与设备使用。
- 奖励函数综合考虑油污接近、协作、效率、安全、消耗等多维目标，支持奖励塑造。

5. 训练流程与并行机制
- 主循环：环境重置→多智能体选动作→环境步进→经验存储→批量采样→网络更新→日志与模型保存。
- 支持多进程环境采样，提升数据效率。
- 训练曲线自动保存为图片，便于后续分析。

6. 关键技术难点与创新点
- 异构多智能体建模与协作机制。
- 图神经网络与时序注意力机制的集成。
- 复杂环境下的奖励塑造与高效采样。
- 支持真实物理仿真与高效简化模拟的环境切换。

本项目为多智能体强化学习在复杂应急决策中的应用提供了可扩展的技术框架和实现范例。 